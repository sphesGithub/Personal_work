{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30176,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%matplotlib inline\nimport numpy as np                   # advanced math library\n\n# for reproducibility\nfrom numpy.random import seed\nseed(42)\nimport tensorflow as tf\ntf.random.set_seed(42)\nrseed = np.random.RandomState(0)\n\nimport matplotlib.pyplot as plt      # MATLAB like plotting routines\nimport random                        # for generating random numbers\nfrom keras.models import Sequential  # Model type to be used\n\nfrom keras.layers.core import Dense, Dropout, Activation # Types of layers to be used in our model\nfrom keras.utils import np_utils                         # NumPy related tools\n\nfrom keras.layers import Dense\nfrom keras.models import Model\nfrom keras.optimizers import adam_v2\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n\n# import CNN tools\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, BatchNormalization\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.applications import EfficientNetV2, InceptionV3, DenseNet201, ResNet50V2\n\n\nfrom sklearn.model_selection import train_test_split # some helper from scikit for data split\n\n#get rid of annoying GPU warnings (and others)\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-28T08:00:59.634719Z","iopub.execute_input":"2024-03-28T08:00:59.635081Z","iopub.status.idle":"2024-03-28T08:01:10.711430Z","shell.execute_reply.started":"2024-03-28T08:00:59.634991Z","shell.execute_reply":"2024-03-28T08:01:10.710340Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/3152897871.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEfficientNetV2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInceptionV3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDenseNet201\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mResNet50V2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'EfficientNetV2' from 'tensorflow.keras.applications' (/opt/conda/lib/python3.7/site-packages/keras/api/_v2/keras/applications/__init__.py)"],"ename":"ImportError","evalue":"cannot import name 'EfficientNetV2' from 'tensorflow.keras.applications' (/opt/conda/lib/python3.7/site-packages/keras/api/_v2/keras/applications/__init__.py)","output_type":"error"}]},{"cell_type":"code","source":"class_names = [\n \"airplane\",\n \"automobile\",\n \"bird\",\n \"cat\",\n \"deer\",\n \"dog\",\n \"frog\",\n \"horse\",\n \"ship\",\n \"truck\"    \n]\n\n(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n\nprint(\"------------------------------\\n\")\nprint(f\"X_train's shape is {X_train.shape}\")\nprint(f\"y_train's shape is {y_train.shape}\")\nprint(f\"X_test's shape is {X_test.shape}\")\nprint(f\"y_test's shape is {y_test.shape}\")\nprint(f\"y_train has {np.max(y_train) + 1} classes\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's take a look at some of these images\nfig, ax = plt.subplots(2, 5, figsize=(15, 6))\nfor i in range(2):\n    for j in range(5):\n        ind = (i * 5) + j\n        ds_ex = np.where(y_train == ind)[0][0]        \n        ax[i, j].imshow(X_train[ds_ex, ...])\n        ax[i, j].set_title(class_names[ind])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = to_one_hot(y_train)\ny_test = to_one_hot(y_test)\n\nprint(f\"y_test's shape is {y_test.shape}\")\nprint(f\"y_train's shape is {y_train.shape}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Aim:\n- Split the training data into train:validation split of 80:20\n- You are limited to a maximum of 20 Epochs!\n- Train using training data but by evaluating the validation set\n- Initialise a better model than ResNet50 for transfer learning.\n- Maximize accuracy on the unseen test set\n- Use transfer learning with appropriate frozen layers for faster training.\n- Use batch normalization to improve training speed and accuracy.\n- Use data augmentation to increase dataset diversity.\n- Produce (four) line graphs of training and test losses and accuracies on a single plot!","metadata":{}},{"cell_type":"code","source":"# Split the training data into train:validation split of 80:20\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=rseed)\n\nprint(\"New shapes\\n\")\nprint(\"X_train shape\", X_train.shape)\nprint(\"y_train shape\", y_train.shape)\nprint(\"X_val shape\", X_val.shape)\nprint(\"y_val shape\", y_val.shape)\nprint(\"X_test shape\", X_test.shape)\nprint(\"y_test shape\", y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we'll use this optimizer\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# we will also perform this in batch\nbatch_sz = 128\nnum_epochs = 12\n\nmodel.fit(X_train, y_train, \n          batch_size=batch_sz, \n          epochs=num_epochs, \n          validation_data=(X_val, y_val), verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#This is the score for the model on the val data\nscore = model.evaluate(X_val, y_val)\nprint('Val score:', score[0])\nprint('Val accuracy:', score[1])\n#This is the score for the model on the test data\nscore = model.evaluate(X_test, y_test)\nprint('Test score:', score[0])\nprint('Test accuracy:', score[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#this is my re-run before I fullyb Maximize the accuracy- I have modified the convolution layers and addes \n# some more attributes that I believe will help\n# Initialize the model\nmodelv2 = Sequential()\n# Convolution Layer 1\nmodelv2.add(Conv2D(filters=64, kernel_size=(3, 3), padding='same', strides=(1, 1), input_shape=(28, 28, 1)))\nmodelv2.add(Activation('relu'))\nmodelv2.add(BatchNormalization(axis=-1))\n\n# Convolution Layer 2\nmodelv2.add(Conv2D(filters=64, kernel_size=(3, 3), padding='same', strides=(1, 1)))\nmodelv2.add(Activation('relu'))\nmodelv2.add(BatchNormalization(axis=-1))\nmodelv2.add(MaxPooling2D(pool_size=(2, 2))) \n\n# Convolution Layer 3\nmodelv2.add(Conv2D(filters=128, kernel_size=(3, 3), padding='same', strides=(1, 1)))\nmodelv2.add(Activation('relu'))\nmodelv2.add(BatchNormalization(axis=-1))\nmodelv2.add(MaxPooling2D(pool_size=(2, 2)))\n\n# Flatten layer to transition to fully connected layers\n\n\n# Fully connected layers\nmodelv2.add(Dense(units=512, activation='relu'))\nmodelv2.add(Dropout(0.5))  # Adding dropout for regularization\nmodelv2.add(Flatten())\nmodelv2.add(Dense(units=10, activation='softmax'))  # Output layer\n\n# Compile the model\nmodelv2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodelv2.fit(X_train, y_train, \n          batch_size=batch_sz, \n          epochs=num_epochs, \n          validation_data=(X_val, y_val), verbose=1)\n#This is the second score for the model on the val data\nprint('------------------------------------------------score----------------------------------------')\nscore = modelv2.evaluate(X_val, y_val)\nprint('Val score:', score[0])\nprint('Val accuracy:', score[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### this time around the accuracy was was much higher for both Test and Validation and now we can try to maximize","metadata":{}},{"cell_type":"markdown","source":"### Maximisation of Accuracy on the Test data ","metadata":{}},{"cell_type":"code","source":"gen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=5,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.05, # Randomly zoom image\n        width_shift_range=0.05,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.05,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False\n)  # randomly flip images\n\ngen2 = ImageDataGenerator()\n\ntrain_gen = gen.flow(X_train, y_train, batch_size=batch_sz)\n\n# Fit the model\nhistory = modelv2.fit(train_gen, batch_size=batch_sz, epochs=num_epochs, validation_data=(X_val, y_val), verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on test data\ntest_score = modelv2.evaluate(X_test, y_test)\n\n# Print test score and accuracy\nprint('Test score:', test_score[0])\nprint('Test accuracy:', test_score[1])\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}